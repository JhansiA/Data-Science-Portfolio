{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required modules for NLP\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the data from source excel\n",
    "train_df = pd.read_excel('Thinkcol_case_study.xlsx',sheet_name='train')\n",
    "test_df = pd.read_excel('Thinkcol_case_study.xlsx',sheet_name='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1743 entries, 0 to 1742\n",
      "Data columns (total 4 columns):\n",
      "ID          1743 non-null int64\n",
      "Mention     1743 non-null object\n",
      "Target      1743 non-null int64\n",
      "Category    1743 non-null object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 54.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48415 entries, 0 to 48414\n",
      "Data columns (total 4 columns):\n",
      "id            48415 non-null int64\n",
      "Message ID    48415 non-null int64\n",
      "Date          48415 non-null datetime64[ns]\n",
      "Mention       48385 non-null object\n",
      "dtypes: datetime64[ns](1), int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values from test data\n",
    "test_df.dropna(axis = 0, subset=['Mention'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1666\n",
       "1      77\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Target'].value_counts() #imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading spacy module for Portugese language\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the predictors and target variables\n",
    "X = train_df['Mention']\n",
    "y = train_df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the train data into train and validation data\n",
    "from  sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(train_df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Mention</th>\n",
       "      <th>Target</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>3906756</td>\n",
       "      <td>COMPREI UM CEL DA MOTOROLA MOTOG4 PLUS E O APA...</td>\n",
       "      <td>0</td>\n",
       "      <td>Service Location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4281157</td>\n",
       "      <td>NA IDA SEGUINTE ME DISSERAM QUE FOI TROCADO O ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Service Location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>3948439</td>\n",
       "      <td>E n√£o bastando esse transtorno de ficar quase...</td>\n",
       "      <td>0</td>\n",
       "      <td>Service Location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5760094</td>\n",
       "      <td>DOIS MESES DEPOIS O CELULAR MOTO G 5 S PLUS N...</td>\n",
       "      <td>0</td>\n",
       "      <td>Service Location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4201964</td>\n",
       "      <td>AI  ELES ME DISSERAM PARA EU LEVAR O APARELHO...</td>\n",
       "      <td>0</td>\n",
       "      <td>Service Location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                            Mention  Target  \\\n",
       "341  3906756  COMPREI UM CEL DA MOTOROLA MOTOG4 PLUS E O APA...       0   \n",
       "147  4281157  NA IDA SEGUINTE ME DISSERAM QUE FOI TROCADO O ...       0   \n",
       "360  3948439   E n√£o bastando esse transtorno de ficar quase...       0   \n",
       "83   5760094   DOIS MESES DEPOIS O CELULAR MOTO G 5 S PLUS N...       0   \n",
       "48   4201964   AI  ELES ME DISSERAM PARA EU LEVAR O APARELHO...       0   \n",
       "\n",
       "             Category  \n",
       "341  Service Location  \n",
       "147  Service Location  \n",
       "360  Service Location  \n",
       "83   Service Location  \n",
       "48   Service Location  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define function to cleanup text by removing personal pronouns, stopwords, and punctuations\n",
    "# def cleanup_text(docs, logging=False):\n",
    "#     texts = []\n",
    "    \n",
    "#     for doc in docs:\n",
    "#         doc = nlp(doc, disable=['parser', 'ner'])\n",
    "#         tokens = [tok.lemma_.lower().strip() for tok in doc]\n",
    "#         tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "#         tokens = ' '.join(tokens)\n",
    "#         texts.append(tokens)\n",
    "#     return pd.Series(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO_text = [text for text in train['Mention']]\n",
    "\n",
    "# INFO_clean = cleanup_text(INFO_text)\n",
    "# INFO_clean = ' '.join(INFO_clean).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules and machine learning classification models \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from spacy.lang.pt import Portuguese\n",
    "parser = Portuguese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"‚Äù\", \"‚Äù\",\"üòç\",\"‚ù§Ô∏è\",\"üòê\",\"‚úåÔ∏è\",\"‚ù§\",\"üëä\",\"‚úã\",\"üì±üì≤\",\"üëå\",\"üöÇ\",\"üì±‚û°Ô∏è\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "class CleanTextTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [cleanText(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "    \n",
    "def cleanText(text):\n",
    "    if type(text)=='str':\n",
    "        text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "        text = text.lower()\n",
    "    else:\n",
    "        text = str(text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and lemmatization by removing personal pronouns, stopwords, and punctuations\n",
    "def tokenizeText(sample):\n",
    "    tokens = parser(sample)\n",
    "    lemmas = []\n",
    "    for tok in tokens:\n",
    "        #if tok.isalpha():\n",
    "        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_)\n",
    "    tokens = lemmas\n",
    "    tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji \n",
    "def give_emoji_free_text(text):\n",
    "    allchars = [str for str in text.decode('utf-8')]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI]\n",
    "    clean_text = ' '.join([str for str in text.decode('utf-8').split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('NB', MultinomialNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorization\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))\n",
    "# Preparing the data for train and validation by selecting the predictor and target variables\n",
    "train1 = train['Mention'].tolist() # train data\n",
    "labelsTrain1 = train['Target'].tolist()\n",
    "\n",
    "test1 = test['Mention'].tolist() #validation data\n",
    "labelsTest1 = test['Target'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe to maintain evaluation metrics for different algorithms\n",
    "Eval_metrics = pd.DataFrame(columns= ['Model','Precision','Recall','F1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help function for evaluation metrics data\n",
    "def classification_report_df(report, name):\n",
    "    dict = {}\n",
    "    lines = report.split('\\n')\n",
    "    row_data = lines[-2].split('      ')\n",
    "    dict = {'Model':name,'Precision' : float(row_data[1]),'Recall' : float(row_data[2]),'F1-score' : float(row_data[3]) }\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.980903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhansi\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.975694\n",
      "NB: 0.968750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jhansi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.968750\n"
     ]
    }
   ],
   "source": [
    "# Training and validating the data for different machine learning classification algorithms\n",
    "for name , clf in models:\n",
    "    pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])\n",
    "    # training\n",
    "    pipe.fit(train1, labelsTrain1)\n",
    "    # validation testing\n",
    "    preds = pipe.predict(test1)\n",
    "    #Evaluation metrics for model\n",
    "    report = metrics.classification_report(labelsTest1, preds)\n",
    "    Evaluations = classification_report_df(report,name)\n",
    "    Eval_metrics = Eval_metrics.append(Evaluations,ignore_index= True)        \n",
    "    msg = \"%s: %f\" % (name, accuracy_score(labelsTest1, preds))\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Precision  Recall  F1-score\n",
       "0  Logistic Regression       0.98    0.98      0.98\n",
       "1                  XGB       0.97    0.98      0.97\n",
       "2                   NB       0.96    0.97      0.96\n",
       "3                  SVM       0.94    0.97      0.95"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the metrics for each classification model\n",
    "Eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.980903\n"
     ]
    }
   ],
   "source": [
    "#From the above evaluation metrics using Logisticregression as best model and training the data only using Logisticregression\n",
    "pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', LogisticRegression())])\n",
    "# training the data\n",
    "pipe.fit(train1, labelsTrain1)\n",
    "# validating the data\n",
    "preds = pipe.predict(test1)\n",
    "msg = \"%s: %f\" % ('accuracy', accuracy_score(labelsTest1, preds))\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing test data\n",
    "final_test = test_df['Mention'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the target variable for test data\n",
    "predictions = pipe.predict(final_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
